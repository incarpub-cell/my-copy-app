import streamlit as st
import google.generativeai as genai

# [ë³´ì•ˆ ì„¤ì •] ê¹ƒí—ˆë¸Œì— ë…¸ì¶œë˜ì§€ ì•Šë„ë¡ Streamlit Secretsì—ì„œ í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
# ì£¼ì˜: ê¹ƒí—ˆë¸Œ ì½”ë“œì—ëŠ” ì•„ë˜ 'GEMINI_API_KEY'ë¼ëŠ” ì´ë¦„í‘œë§Œ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.
try:
    MY_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=MY_KEY)
except Exception as e:
    st.error("API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Settings > Secretsì— í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop() # í‚¤ê°€ ì—†ìœ¼ë©´ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.

# [í•µì‹¬ ë¡œì§] 404 ì—ëŸ¬ë¥¼ ë°©ì§€í•˜ëŠ” ëª¨ë¸ ìë™ ê°ì§€ í•¨ìˆ˜
@st.cache_resource
def get_working_model():
    # í˜„ì¬ ë‚´ ê³„ì •ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
    all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    
    # ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ ìˆœì„œëŒ€ë¡œ ìë™ ë§¤ì¹­í•©ë‹ˆë‹¤.
    if 'models/gemini-1.5-flash' in all_models:
        return genai.GenerativeModel('models/gemini-1.5-flash')
    elif 'models/gemini-pro' in all_models:
        return genai.GenerativeModel('models/gemini-pro')
    else:
        # ê·¸ ì™¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ëª¨ë¸ì„ ê°•ì œë¡œ ì—°ê²°í•˜ì—¬ ì˜¤ë¥˜ë¥¼ ì°¨ë‹¨í•©ë‹ˆë‹¤.
        return genai.GenerativeModel(all_models[0])

# [UI] ì›¹ í™”ë©´ êµ¬ì„±
st.set_page_config(page_title="ì œíœ´ë§ˆì¼€íŒ… ì¹´í”¼ ìë™í™” ì‹œìŠ¤í…œ", page_icon="ğŸª")
st.title("ğŸªì˜ íŒ”ë¦¬ëŠ” 'ì œí’ˆ ì¹´í”¼' ìƒì„±ê¸°")

st.markdown("---") # êµ¬ë¶„ì„ 

product_name = st.text_input("1. ì œí’ˆ ì´ë¦„", placeholder="ì˜ˆ: ì €ë‹¹ íƒ€íŠ¸ì²´ë¦¬ ì ¤ë¦¬")
product_features = st.text_area("2. ì œí’ˆì˜ í•µì‹¬ íŠ¹ì§•", placeholder="ìƒì„¸í˜ì´ì§€ ë‚´ìš©ì„ ë³µì‚¬í•´ ë„£ìœ¼ì„¸ìš”.")
target_style = st.selectbox("3. ë§ˆì¼€íŒ… ìŠ¤íƒ€ì¼", ["MZì„¸ëŒ€ (í™í•˜ê²Œ)", "ì§ì¥ì¸ (ê³µê°)", "ì£¼ë¶€/ë¶€ëª¨ë‹˜ (ì‹ ë¢°)"])

st.markdown("---")

if st.button("ì „ë¬¸ ë§ˆì¼€í„°ì˜ ì¹´í”¼ ìƒì„± âœ¨"):
    if product_name and product_features:
        with st.spinner('AI ë§ˆì¼€í„°ê°€ ì¹´í”¼ë¥¼ êµ½ê³  ìˆìŠµë‹ˆë‹¤...'):
            try:
                model = get_working_model()
                prompt = f"""
                ë„ˆëŠ” ê´‘ê³  ëŒ€í–‰ì‚¬ íŒ€ì¥ì´ì•¼. ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¹ì¥ êµ¬ë§¤í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ì¹´í”¼ë¥¼ ì§œì¤˜.
                ì œí’ˆëª…: {product_name}
                í•µì‹¬ ì¥ì : {product_features}
                íƒ€ê²Ÿ ìŠ¤íƒ€ì¼: {target_style}
                
                ì œí’ˆ ì»¨ì…‰, íŠ¹ì§•ì„ ì‚´ë ¤ ì¸ìŠ¤íƒ€/ë¸”ë¡œê·¸ìš© ë¬¸êµ¬ì™€ í•´ì‹œíƒœê·¸ë¥¼ ë§Œë“¤ì–´ì¤˜.
                ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ì‘ì„±í•´ì¤˜.
                """
                response = model.generate_content(prompt)
                st.balloons()
                st.success("ë§›ìˆëŠ” ì¹´í”¼ê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.markdown(response.text)
            except Exception as e:
                # 403 Leaked ì—ëŸ¬ ë°œìƒ ì‹œ ì•ˆë‚´ ë¬¸êµ¬
                if "403" in str(e) or "leaked" in str(e).lower():
                    st.error("í˜„ì¬ API í‚¤ê°€ ì°¨ë‹¨ëœ ìƒíƒœì…ë‹ˆë‹¤. Google AI Studioì—ì„œ ìƒˆ í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ Secretsì— ì—…ë°ì´íŠ¸í•´ì£¼ì„¸ìš”.")
                else:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    else:
        st.warning("ì œí’ˆ ì •ë³´ì™€ íŠ¹ì§•ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”!")




